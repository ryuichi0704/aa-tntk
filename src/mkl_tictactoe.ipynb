{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100e354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.018188Z",
     "start_time": "2024-05-10T15:48:46.014694Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_latex():\n",
    "    for i in range(2):\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.rc('text', usetex=True)\n",
    "        plt.rc('font', family='serif')\n",
    "\n",
    "        plt.style.use(\"default\")\n",
    "        plt.rcParams[\"font.size\"] = 15\n",
    "\n",
    "        plt.rcParams['font.family'] = 'Times New Roman'\n",
    "        plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "\n",
    "        try:\n",
    "            del matplotlib.font_manager.weight_dict['roman']\n",
    "            matplotlib.font_manager._rebuild()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09644e57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.831316Z",
     "start_time": "2024-05-10T15:48:46.020187Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b171b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.836311Z",
     "start_time": "2024-05-10T15:48:46.833971Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"font.size\"]=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950719d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.839367Z",
     "start_time": "2024-05-10T15:48:46.837206Z"
    }
   },
   "outputs": [],
   "source": [
    "set_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889274f2",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bb4869",
   "metadata": {},
   "source": [
    "For downloading dataset, see https://github.com/LeoYu/neural-tangent-kernel-UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe4f30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.843497Z",
     "start_time": "2024-05-10T15:48:46.840256Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"./data/\")\n",
    "\n",
    "def get_datasize(dic: Dict) -> Tuple[int, int, int, int]:\n",
    "    c = int(dic[\"n_clases=\"])\n",
    "    d = int(dic[\"n_entradas=\"])\n",
    "    n_train_val = int(dic[\"n_patrons1=\"])\n",
    "    if \"n_patrons2=\" in dic:\n",
    "        n_test = int(dic[\"n_patrons2=\"])\n",
    "    else:\n",
    "        n_test = 0\n",
    "    n_tot = n_train_val + n_test\n",
    "    return n_tot, n_train_val, n_test, d, c\n",
    "\n",
    "\n",
    "def load_data(dic: Dict) -> Tuple[np.array, np.array]:\n",
    "    f = open(os.path.join(DATA_DIR, dic[\"dataset\"], dic[\"fich1=\"]), \"r\").readlines()[1:]\n",
    "    X = np.asarray(list(map(lambda x: list(map(float, x.split()[1:-1])), f)))\n",
    "    y = np.asarray(list(map(lambda x: int(x.split()[-1]), f)))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c2916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.851759Z",
     "start_time": "2024-05-10T15:48:46.844299Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_TOT = 1000\n",
    "MAX_FEATURES = 10\n",
    "MAX_CLASSES = 2\n",
    "\n",
    "datasets = []\n",
    "\n",
    "n_dataset = 0\n",
    "for idx, dataset in enumerate(sorted(os.listdir(DATA_DIR))): \n",
    "    if not os.path.isfile(os.path.join(DATA_DIR, dataset, f\"{dataset}.txt\")):\n",
    "        continue\n",
    "\n",
    "    # load configuration\n",
    "    dic = dict()\n",
    "    dic[\"dataset\"] = dataset\n",
    "    if dic[\"dataset\"]!=\"tic-tac-toe\": # use only tic-tac-toe\n",
    "        continue\n",
    "\n",
    "    for k, v in map(\n",
    "        lambda x: x.split(),\n",
    "        open(os.path.join(DATA_DIR, dataset, f\"{dataset}.txt\"), \"r\").readlines(),\n",
    "    ):\n",
    "        dic[k] = v\n",
    "\n",
    "    # Check skip or not\n",
    "    n_tot, n_train_val, n_test, n_feature, n_class = get_datasize(dic)\n",
    "    if (n_tot > MAX_TOT) or (n_test > 0) or (n_feature >  MAX_FEATURES) or (n_class > MAX_CLASSES):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"-----{idx}, {dataset}, {n_tot}, {n_feature}, {n_class}-----\")\n",
    "        n_dataset += 1\n",
    "\n",
    "    # load dataset\n",
    "    X, y = load_data(dic)\n",
    "    fold = list(\n",
    "        map(\n",
    "            lambda x: list(map(int, x.split())),\n",
    "            open(\n",
    "                os.path.join(DATA_DIR, dic[\"dataset\"], \"conxuntos_kfold.dat\"), \"r\"\n",
    "            ).readlines(),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b3fc9",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c7c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.855566Z",
     "start_time": "2024-05-10T15:48:46.852582Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tau(alpha: float, S: np.array, diag_i: np.array, diag_j: np.array) -> np.array:\n",
    "    tau = 1 / 4 + 1 / (2 * math.pi) * np.arcsin(\n",
    "        ((alpha**2) * S)\n",
    "        / (np.sqrt(((alpha**2) * diag_i + 0.5) * ((alpha**2) * diag_j + 0.5)))\n",
    "    )\n",
    "    return tau\n",
    "\n",
    "\n",
    "def calc_tau_dot(\n",
    "    alpha: float, S: np.array, diag_i: np.array, diag_j: np.array\n",
    ") -> np.array:\n",
    "    tau_dot = (\n",
    "        (alpha**2)\n",
    "        / (math.pi)\n",
    "        * 1\n",
    "        / np.sqrt(\n",
    "            (2 * (alpha**2) * diag_i + 1) * (2 * (alpha**2) * diag_j + 1)\n",
    "            - (4 * (alpha**4) * (S**2))\n",
    "        )\n",
    "    )\n",
    "    return tau_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1672f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.861018Z",
     "start_time": "2024-05-10T15:48:46.856538Z"
    }
   },
   "outputs": [],
   "source": [
    "def hard_kernel(X: np.array, alpha: float, beta: float, finetune: bool, rulelist: list):\n",
    "    S_list = []\n",
    "    tau_list = []\n",
    "    tau_dot_list = []\n",
    "\n",
    "    for feature_index in range(len(X[0])):\n",
    "        S = np.outer(X[:, feature_index], X[:, feature_index].T) + beta**2\n",
    "        S_all = np.matmul(X, X.T) + beta**2\n",
    "        if finetune:\n",
    "            S_list.append(S_all)\n",
    "        else:\n",
    "            S_list.append(S)\n",
    "\n",
    "        _diag = [S[i, i] for i in range(len(S))]\n",
    "        diag_i = np.array(_diag * len(_diag)).reshape(len(_diag), len(_diag))\n",
    "        diag_j = diag_i.transpose()\n",
    "        tau_list.append(calc_tau(alpha, S, diag_i, diag_j))\n",
    "        tau_dot_list.append(calc_tau_dot(alpha, S, diag_i, diag_j))\n",
    "\n",
    "    K = np.zeros((X.shape[0], X.shape[0]))\n",
    "\n",
    "    H = np.zeros_like(S_list[0])\n",
    "    for rules in tqdm(rulelist, leave=False):\n",
    "        # Internal nodes\n",
    "        for i, s in enumerate(rules):\n",
    "            ts = rules[0:i] + rules[i + 1 :]\n",
    "            _H_nodes = S_list[s] * tau_dot_list[s]\n",
    "            for t in ts:\n",
    "                _H_nodes *= tau_list[t]\n",
    "            K += _H_nodes * (2 ** len(rules))\n",
    "        _H_leaves = np.ones_like(K)\n",
    "\n",
    "        # Leaves\n",
    "        for tau in [tau_list[i] for i in rules]:\n",
    "            _H_leaves *= tau\n",
    "        K += _H_leaves * (2 ** len(rules))\n",
    "\n",
    "    return K / len(rulelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951fdd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.866275Z",
     "start_time": "2024-05-10T15:48:46.862614Z"
    }
   },
   "outputs": [],
   "source": [
    "def soft_kernel(X: np.array, depth: int, alpha: float, beta: float):\n",
    "    K = np.zeros((depth, X.shape[0], X.shape[0]))\n",
    "    S = np.matmul(X, X.T) + beta**2\n",
    "    _diag = [S[i, i] for i in range(len(S))]\n",
    "    diag_i = np.array(_diag * len(_diag)).reshape(len(_diag), len(_diag))\n",
    "    diag_j = diag_i.transpose()\n",
    "\n",
    "    tau = calc_tau(alpha, S, diag_i, diag_j)\n",
    "    tau_dot = calc_tau_dot(alpha, S, diag_i, diag_j)\n",
    "\n",
    "    for i, depth in enumerate((range(1, depth + 1, 1))):\n",
    "        H = (2 * S * (2 ** (depth - 1)) * depth * tau_dot * tau ** (depth - 1)) + (\n",
    "            (2**depth) * (tau**depth)\n",
    "        )\n",
    "        K[depth - 1] = H\n",
    "\n",
    "    return K[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef60394",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:46.873067Z",
     "start_time": "2024-05-10T15:48:46.869452Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_kernels(X, alpha, beta, degree):\n",
    "    assert degree in (1, 2, 3)\n",
    "    patterns = list(itertools.combinations(np.arange(X.shape[1]), 1))\n",
    "\n",
    "    if degree >= 2:\n",
    "        patterns.extend(list(itertools.combinations(np.arange(X.shape[1]), 2)))\n",
    "\n",
    "    if degree >= 3:\n",
    "        patterns.extend(list(itertools.combinations(np.arange(X.shape[1]), 3)))\n",
    "\n",
    "    patterns = [list(l) for l in patterns]\n",
    "    patterns = [[pattern] for pattern in patterns]\n",
    "\n",
    "    kernels_aaa = []\n",
    "    kernels_aai = []\n",
    "\n",
    "    for pattern in tqdm(patterns, leave=False):\n",
    "        kernels_aaa.append(\n",
    "            hard_kernel(X, alpha=alpha, beta=beta, finetune=False, rulelist=pattern)\n",
    "        )\n",
    "        kernels_aai.append(\n",
    "            hard_kernel(X, alpha=alpha, beta=beta, finetune=True, rulelist=pattern)\n",
    "        )\n",
    "\n",
    "    return kernels_aaa, kernels_aai, patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e233068",
   "metadata": {},
   "source": [
    "## MKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3ca5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:48:47.763800Z",
     "start_time": "2024-05-10T15:48:46.874027Z"
    }
   },
   "outputs": [],
   "source": [
    "from MKLpy.algorithms import EasyMKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4fa74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:31.917135Z",
     "start_time": "2024-05-10T15:48:47.764830Z"
    }
   },
   "outputs": [],
   "source": [
    "kernels_aaa, kernels_aai, patterns = extract_kernels(X, alpha=2.0, beta=0.5, degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2e646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:32.492194Z",
     "start_time": "2024-05-10T15:50:31.918629Z"
    }
   },
   "outputs": [],
   "source": [
    "mkl = EasyMKL()\n",
    "ker_matrix_aaa_full = mkl.combine_kernels(kernels_aaa, y)\n",
    "ker_matrix_aai_full = mkl.combine_kernels(kernels_aai, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aaa359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.479245Z",
     "start_time": "2024-05-10T15:50:32.493386Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,2))\n",
    "x = range(len(ker_matrix_aaa_full.weights))\n",
    "plt.bar(x, ker_matrix_aaa_full.weights, alpha=0.5, label=\"AAA\")\n",
    "plt.bar(x, ker_matrix_aai_full.weights, alpha=0.5, label=\"AAI\")\n",
    "plt.xticks(\n",
    "    x,\n",
    "    [str(sorted(set(i[0]))).replace(\"[\", \"{\").replace(\"]\", \"}\") for i in patterns],\n",
    "    rotation=75,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.xlim(-1.5, len(patterns)+0.5)\n",
    "plt.axvline(45, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(60, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(66, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(86, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(100, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(105, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(109, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.axvline(128, color=\"red\", linestyle=\"dashed\", linewidth=1)\n",
    "\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.ylabel(\"Weight\")\n",
    "x = range(len(ker_matrix_aai_full.weights))\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.xlabel(\"Feature Combination\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./figures/tictactoe_weight.pdf\", bbox_inches=\"tight\", pad_inches=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271ba0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.482680Z",
     "start_time": "2024-05-10T15:50:33.480356Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimal_weight(size):\n",
    "    optimal = np.zeros_like(range(size))/1.\n",
    "    optimal[45] = 1\n",
    "    optimal[60] = 1\n",
    "    optimal[66] = 1\n",
    "    optimal[86] = 1\n",
    "    optimal[100] = 1\n",
    "    optimal[105] = 1\n",
    "    optimal[109] = 1\n",
    "    optimal[128] = 1\n",
    "    optimal/=sum(optimal)\n",
    "    return optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148db565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.486434Z",
     "start_time": "2024-05-10T15:50:33.483586Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def svm(kernels, y, weights, reg, train_index, test_index):\n",
    "    model = SVC(kernel=\"precomputed\", C=1.0, probability=True)\n",
    "\n",
    "    K = np.zeros_like(kernels[0])\n",
    "    for j in range(len(weights)):\n",
    "        K += kernels[j] * weights[j]\n",
    "\n",
    "    K_train = K[train_index][:, train_index]\n",
    "    K_test = K[test_index][:, train_index]\n",
    "\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model.fit(K_train, y_train)\n",
    "    test_pred = model.predict(K_test)\n",
    "    test_pred_proba = model.predict_proba(K_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, test_pred)\n",
    " \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6459c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.543401Z",
     "start_time": "2024-05-10T15:50:33.487328Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "def rf_benchmark(\n",
    "    X: np.array,\n",
    "    y: np.array,\n",
    "    train_index: list,\n",
    "    test_index: list,\n",
    "    max_depth: int,\n",
    "    n_estimators: int,\n",
    "    max_features: int,\n",
    ") -> Tuple[float, List[float]]:\n",
    "    model = RandomForestClassifier(\n",
    "        max_depth=max_depth, n_estimators=n_estimators, max_features=max_features\n",
    "    )\n",
    "    model.fit(X[train_index], y[train_index])\n",
    "    test_pred = model.predict(X[test_index])\n",
    "    test_pred_proba = model.predict_proba(X[test_index])[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y[test_index], test_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def gbdt_benchmark(\n",
    "    X: np.array,\n",
    "    y: np.array,\n",
    "    train_index: list,\n",
    "    test_index: list,\n",
    "    max_depth: int,\n",
    "    n_estimators: int,\n",
    "    max_features: int,\n",
    ") -> Tuple[float, List[float]]:\n",
    "    model = GradientBoostingClassifier(\n",
    "        max_depth=max_depth, n_estimators=n_estimators, max_features=max_features\n",
    "    )\n",
    "    model.fit(X[train_index], y[train_index])\n",
    "    test_pred = model.predict(X[test_index])\n",
    "    test_pred_proba = model.predict_proba(X[test_index])[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y[test_index], test_pred)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1e1db",
   "metadata": {},
   "source": [
    "## Forest benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb4577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.550493Z",
     "start_time": "2024-05-10T15:50:33.544656Z"
    }
   },
   "outputs": [],
   "source": [
    "def forest_benchmark(y, train_index, test_index):\n",
    "    acc_dict = {}\n",
    "    \n",
    "    max_features=\"sqrt\"\n",
    "    \n",
    "    for max_depth in (3,5,7,None):\n",
    "        for n_estimators in (125, 250, 500, 1000, 2000, 4000):\n",
    "            acc_dict[f\"rf_{max_depth}_{n_estimators}\"] = rf_benchmark(X, y, train_index, test_index, max_depth=max_depth, n_estimators=n_estimators, max_features=max_features)\n",
    "            acc_dict[f\"gbdt_{max_depth}_{n_estimators}\"] = gbdt_benchmark(X, y, train_index, test_index, max_depth=max_depth, n_estimators=n_estimators, max_features=max_features)\n",
    "\n",
    "    return acc_dict\n",
    "\n",
    "if False:\n",
    "    acc_dicts = []\n",
    "\n",
    "    for i in tqdm(range(12), leave=False):\n",
    "        for repeat in tqdm(range(4), leave=False):\n",
    "            test_index, train_index = fold[repeat * 2], fold[repeat * 2 + 1]\n",
    "            assert len(test_index) > len(train_index)\n",
    "            acc_dict = forest_benchmark(y, train_index, test_index)\n",
    "            acc_dict[\"seed\"] = i\n",
    "            acc_dicts.append(acc_dict)\n",
    "\n",
    "        with open('forest_acc_dicts.pkl', 'wb') as file:\n",
    "            pickle.dump(acc_dicts, file)\n",
    "            \n",
    "with open('forest_acc_dicts.pkl', 'rb') as file:\n",
    "    forest_acc_dicts= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3698103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.599130Z",
     "start_time": "2024-05-10T15:50:33.551453Z"
    }
   },
   "outputs": [],
   "source": [
    "all_experiments_df = pd.DataFrame()\n",
    "for i, data in enumerate(forest_acc_dicts):\n",
    "    temp_df = pd.Series(data).reset_index()\n",
    "    temp_df.columns = ['label', f'value_{i}']\n",
    "    if all_experiments_df.empty:\n",
    "        all_experiments_df = temp_df\n",
    "    else:\n",
    "        all_experiments_df = all_experiments_df.merge(temp_df, on='label')\n",
    "\n",
    "forest_mean = pd.DataFrame(all_experiments_df.set_index(\"label\").T).groupby(by=\"seed\").mean().mean()\n",
    "forest_std = pd.DataFrame(all_experiments_df.set_index(\"label\").T).groupby(by=\"seed\").mean().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278ed3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.603744Z",
     "start_time": "2024-05-10T15:50:33.600124Z"
    }
   },
   "outputs": [],
   "source": [
    "def benchmark(kernels_aaa, kernels_aai,kernel_soft,  y, train_index, test_index, alpha, beta, repeat, optimal):\n",
    "    acc_dict = {}\n",
    "    \n",
    "    acc_dict[\"alpha\"] = alpha\n",
    "    acc_dict[\"beta\"] = beta\n",
    "    acc_dict[\"repeat\"] = repeat\n",
    "    \n",
    "    # AAA\n",
    "    acc_dict[\"aaa_mkl\"] = svm(kernels_aaa, y, np.array(ker_matrix_aaa.weights), 1.0, train_index, test_index)\n",
    "    acc_dict[\"aaa_optimal\"] = svm(kernels_aaa, y, optimal, 1.0, train_index, test_index)\n",
    "    acc_dict[\"aaa_benchmark\"] = svm(kernels_aaa, y, np.ones_like(ker_matrix_aaa.weights)/len(ker_matrix_aaa.weights), 1.0, train_index, test_index)\n",
    "\n",
    "    # AAI\n",
    "    acc_dict[\"aai_mkl\"] = svm(kernels_aai, y, np.array(ker_matrix_aai.weights), 1.0, train_index, test_index)\n",
    "    acc_dict[\"aai_optimal\"] = svm(kernels_aai, y, optimal, 1.0, train_index, test_index)\n",
    "    acc_dict[\"aai_benchmark\"] = svm(kernels_aai, y, np.ones_like(ker_matrix_aai.weights)/len(ker_matrix_aaa.weights), 1.0, train_index, test_index)\n",
    "\n",
    "    # Soft\n",
    "    acc_dict[\"soft\"] = svm([kernel_soft] * len(kernels_aaa), y, np.ones_like(ker_matrix_aaa.weights)/len(ker_matrix_aaa.weights), 1.0, train_index, test_index)\n",
    "    return acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb003fca",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abc3a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.608422Z",
     "start_time": "2024-05-10T15:50:33.604675Z"
    }
   },
   "outputs": [],
   "source": [
    "degree = 3\n",
    "\n",
    "acc_dicts = []\n",
    "\n",
    "if False:\n",
    "    for alpha in tqdm([0.5, 1.0, 2.0, 4.0], leave=False):\n",
    "        for beta in tqdm([0.1, 0.5, 1.0], leave=False):\n",
    "            kernel_soft = soft_kernel(X, depth=degree, alpha=alpha, beta=beta)\n",
    "            kernels_aaa, kernels_aai, patterns = extract_kernels(X, alpha=alpha, beta=beta, degree=degree)\n",
    "\n",
    "            for repeat in tqdm(range(4), leave=False):\n",
    "                test_index, train_index = fold[repeat * 2], fold[repeat * 2 + 1]\n",
    "                assert len(test_index) > len(train_index)\n",
    "                mkl = EasyMKL()\n",
    "\n",
    "                train_kernels_aaa = [i[train_index][:, train_index] for i in kernels_aaa]\n",
    "                train_kernels_aai = [i[train_index][:, train_index] for i in kernels_aai]\n",
    "                ker_matrix_aaa = mkl.combine_kernels(train_kernels_aaa, y[train_index])\n",
    "                ker_matrix_aai = mkl.combine_kernels(train_kernels_aai, y[train_index])                    \n",
    "\n",
    "                optimal = get_optimal_weight(len(ker_matrix_aaa.weights))\n",
    "\n",
    "                acc_dict = benchmark(kernels_aaa, kernels_aai, kernel_soft, y, train_index, test_index, alpha, beta, repeat, optimal)\n",
    "\n",
    "                acc_dicts.append(acc_dict)\n",
    "\n",
    "    with open('acc_dicts.pkl', 'wb') as file:\n",
    "        pickle.dump(acc_dicts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965089d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.611036Z",
     "start_time": "2024-05-10T15:50:33.609214Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('acc_dicts.pkl', 'rb') as file:\n",
    "    acc_dicts= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685757a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:33.969618Z",
     "start_time": "2024-05-10T15:50:33.612046Z"
    }
   },
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "\n",
    "df = pd.DataFrame(acc_dicts)\n",
    "\n",
    "_df = df[df[\"beta\"]==beta].groupby(by=[\"alpha\", \"beta\"]).mean()[\n",
    "    [\"aaa_mkl\", \"aaa_optimal\", \"aaa_benchmark\", \"aai_mkl\", \"aai_optimal\", \"aai_benchmark\", \"soft\"]\n",
    "].reset_index()\n",
    "\n",
    "x = range(4)\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "_df[\"aaa_mkl\"].plot(label=\"AAA (MKL)\", color=\"red\", linestyle=\"solid\", marker=\"o\")\n",
    "_df[\"aaa_optimal\"].plot(label=\"AAA (Optimal)\", color=\"red\", linestyle=\"dashed\", marker=\"^\")\n",
    "_df[\"aaa_benchmark\"].plot(label=\"AAA (Benchmark)\", color=\"red\", linestyle=\"dotted\", marker=\"v\" )\n",
    "_df[\"aai_mkl\"].plot(label=\"AAI (MKL)\", color=\"blue\", linestyle=\"solid\", marker=\"o\")\n",
    "_df[\"aai_optimal\"].plot(label=\"AAI (Optimal)\", color=\"blue\", linestyle=\"dashed\", marker=\"^\")\n",
    "_df[\"aai_benchmark\"].plot(label=\"AAI (Benchmark)\", color=\"blue\", linestyle=\"dotted\", marker=\"v\")\n",
    "_df[\"soft\"].plot(label=\"Oblique\", color=\"black\", marker=\"s\")\n",
    "\n",
    "rf3_mean = forest_mean[\"rf_3_1000\"]\n",
    "rf3_std = forest_std[\"rf_3_1000\"]\n",
    "\n",
    "rfmax_mean = forest_mean[\"rf_None_1000\"]\n",
    "rfmax_std = forest_std[\"rf_None_1000\"]\n",
    "\n",
    "gbdt3_mean = forest_mean[\"gbdt_3_1000\"]\n",
    "gbdt3_std = forest_std[\"gbdt_3_1000\"]\n",
    "\n",
    "gbdtmax_mean = forest_mean[\"gbdt_None_1000\"]\n",
    "gbdtmax_std = forest_std[\"gbdt_None_1000\"]\n",
    "\n",
    "plt.plot(x, [rf3_mean]*len(x), color=\"green\", linestyle=(3, (6, 6)), alpha=0.7, label=\"RF (max_depth=3)\", linewidth=1.5)\n",
    "plt.fill_between(x, rf3_mean - rf3_std, rf3_mean+rf3_std, color='green', alpha=0.1)\n",
    "plt.plot(x, [rfmax_mean]*len(x), color=\"green\", linestyle=(3, (1, 1)), alpha=0.7, label=\"RF (max_depth=None)\", linewidth=1.5)\n",
    "plt.fill_between(x, rfmax_mean-rfmax_std, rfmax_mean+rfmax_std, color='green', alpha=0.1)\n",
    "\n",
    "plt.plot(x, [gbdt3_mean]*len(x), color=\"orange\", linestyle=(0, (6,6)),  alpha=0.7, label=\"GBDT (max_depth=3)\", linewidth=1.5)\n",
    "plt.fill_between(x, gbdt3_mean-gbdt3_std, gbdt3_mean+gbdt3_std, color='orange', alpha=0.1)\n",
    "plt.plot(x, [gbdtmax_mean]*len(x), color=\"orange\", linestyle=(0, (1,1)),  alpha=0.7, label=\"GBDT (max_depth=None)\", linewidth=1.5)\n",
    "plt.fill_between(x, gbdtmax_mean-gbdtmax_std, gbdtmax_mean+gbdtmax_std, color='orange', alpha=0.1)\n",
    "\n",
    "plt.xticks([0, 1, 2, 3], [0.5, 1.0, 2.0, 4.0])\n",
    "plt.xlabel(\"$\\\\alpha$\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1,0.95))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figures/tictactoe_metrics.pdf\", bbox_inches=\"tight\", pad_inches=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7eb90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:34.510812Z",
     "start_time": "2024-05-10T15:50:33.970826Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i, beta in enumerate([0.1, 0.5, 1.0]):\n",
    "    plt.subplot(1,3, i+1)\n",
    "    _df = df[df[\"beta\"]==beta].groupby(by=[\"alpha\", \"beta\"]).mean()[\n",
    "        [\"aaa_mkl\", \"aaa_optimal\", \"aaa_benchmark\", \"aai_mkl\", \"aai_optimal\", \"aai_benchmark\", \"soft\"]\n",
    "    ].reset_index()\n",
    "\n",
    "    x = range(4)\n",
    "\n",
    "    _df[\"aaa_mkl\"].plot(label=\"AAA (MKL)\", color=\"red\", linestyle=\"solid\", marker=\"o\")\n",
    "    _df[\"aaa_optimal\"].plot(label=\"AAA (Optimal)\", color=\"red\", linestyle=\"dashed\", marker=\"^\")\n",
    "    _df[\"aaa_benchmark\"].plot(label=\"AAA (Benchmark)\", color=\"red\", linestyle=\"dotted\", marker=\"v\" )\n",
    "    _df[\"aai_mkl\"].plot(label=\"AAI (MKL)\", color=\"blue\", linestyle=\"solid\", marker=\"o\")\n",
    "    _df[\"aai_optimal\"].plot(label=\"AAI (Optimal)\", color=\"blue\", linestyle=\"dashed\", marker=\"^\")\n",
    "    _df[\"aai_benchmark\"].plot(label=\"AAI (Benchmark)\", color=\"blue\", linestyle=\"dotted\", marker=\"v\")\n",
    "    _df[\"soft\"].plot(label=\"Oblique\", color=\"black\", marker=\"s\")\n",
    "\n",
    "    rf3_mean = forest_mean[\"rf_3_1000\"]\n",
    "    rf3_std = forest_std[\"rf_3_1000\"]\n",
    "\n",
    "    rfmax_mean = forest_mean[\"rf_None_1000\"]\n",
    "    rfmax_std = forest_std[\"rf_None_1000\"]\n",
    "\n",
    "    gbdt3_mean = forest_mean[\"gbdt_3_1000\"]\n",
    "    gbdt3_std = forest_std[\"gbdt_3_1000\"]\n",
    "\n",
    "    gbdtmax_mean = forest_mean[\"gbdt_None_1000\"]\n",
    "    gbdtmax_std = forest_std[\"gbdt_None_1000\"]\n",
    "\n",
    "    plt.plot(x, [rf3_mean]*len(x), color=\"green\", linestyle=(3, (6, 6)), alpha=0.7, label=\"RF (max_depth=3)\", linewidth=1.5)\n",
    "    plt.plot(x, [rfmax_mean]*len(x), color=\"green\", linestyle=(3, (1, 1)), alpha=0.7, label=\"RF (max_depth=None)\", linewidth=1.5)\n",
    "    plt.plot(x, [gbdt3_mean]*len(x), color=\"orange\", linestyle=(0, (6,6)),  alpha=0.7, label=\"GBDT (max_depth=3)\", linewidth=1.5)\n",
    "    plt.plot(x, [gbdtmax_mean]*len(x), color=\"orange\", linestyle=(0, (1,1)),  alpha=0.7, label=\"GBDT (max_depth=None)\", linewidth=1.5)\n",
    "\n",
    "    plt.fill_between(x, rf3_mean - rf3_std, rf3_mean+rf3_std, color='green', alpha=0.1)\n",
    "    plt.fill_between(x, rfmax_mean-rfmax_std, rfmax_mean+rfmax_std, color='green', alpha=0.1)\n",
    "    plt.fill_between(x, gbdt3_mean-gbdt3_std, gbdt3_mean+gbdt3_std, color='orange', alpha=0.1)\n",
    "    plt.fill_between(x, gbdtmax_mean-gbdtmax_std, gbdtmax_mean+gbdtmax_std, color='orange', alpha=0.1)\n",
    "\n",
    "    plt.xticks([0, 1, 2, 3], [0.5, 1.0, 2.0, 4.0])\n",
    "    plt.xlabel(\"$\\\\alpha$\")\n",
    "    if beta==0.1:\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "    plt.grid(linestyle=\"dotted\")\n",
    "    plt.title(f\"$\\\\beta$={beta}\")\n",
    "\n",
    "plt.figlegend(\n",
    "    labels=[\n",
    "        \"AAA (MKL)\", \n",
    "        \"AAA (Benchmark)\", \n",
    "        \"AAA (Optimal)\",\n",
    "        \"AAI (MKL)\",\n",
    "        \"AAI (Benchmark)\",\n",
    "        \"AAI (Optimal)\",\n",
    "        \"Oblique\", \n",
    "        \"RF (max_depth=3)\",\n",
    "        \"RF (max_depth=None)\",        \n",
    "        \"GBDT (max_depth=3)\",\n",
    "        \"GBDT (max_depth=None)\",\n",
    "    ],\n",
    "    loc=\"lower center\", \n",
    "    ncol=4,\n",
    "    bbox_to_anchor=(0.525, -0.2)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figures/tictactoe_metrics_beta.pdf\", bbox_inches=\"tight\", pad_inches=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c88cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:35.220187Z",
     "start_time": "2024-05-10T15:50:34.511951Z"
    }
   },
   "outputs": [],
   "source": [
    "full_series_data = forest_mean\n",
    "full_df = full_series_data.reset_index()\n",
    "full_df.columns = ['label', 'value']\n",
    "full_df['algorithm'] = full_df['label'].apply(lambda x: x.split('_')[0].upper())\n",
    "full_df['max_depth'] = full_df['label'].apply(lambda x: x.split('_')[1])\n",
    "full_df['n_estimators'] = full_df['label'].apply(lambda x: x.split('_')[2])\n",
    "full_df.drop('label', axis=1, inplace=True)\n",
    "\n",
    "full_df['x_label'] = full_df.apply(lambda row: f\"max_depth={row['max_depth']}, n_estimators={row['n_estimators']}\", axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "bar_plot = sns.barplot(y='x_label', x='value', hue='algorithm', data=full_df, ci=None)\n",
    "for i in range(len(forest_mean)):\n",
    "    if i%2:\n",
    "        bar_plot.errorbar(forest_mean[i], i//2+0.2, xerr=forest_std[i], fmt='none', c='black', capsize=3)\n",
    "    else:\n",
    "        bar_plot.errorbar(forest_mean[i], i//2-0.2, xerr=forest_std[i], fmt='none', c='black', capsize=3)\n",
    "        \n",
    "plt.vlines(\n",
    "    _df[\"aaa_benchmark\"].max(), \n",
    "    ymin=-0.5,\n",
    "    ymax=23.5, \n",
    "    color=\"red\", \n",
    "    linestyle=\"dotted\", \n",
    "    alpha=0.7, \n",
    "    label=\"AAA (Benchmark)\",\n",
    "    linewidth=2.0\n",
    ")\n",
    "\n",
    "plt.vlines(\n",
    "    _df[\"aai_benchmark\"].max(), \n",
    "    ymin=-0.5,\n",
    "    ymax=23.5,\n",
    "    color=\"blue\",\n",
    "    linestyle=\"dotted\",\n",
    "    alpha=0.7,\n",
    "    label=\"AAI (Benchmark)\",\n",
    "    linewidth=2.0\n",
    ")\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Parameters')\n",
    "plt.xticks()\n",
    "plt.legend()\n",
    "plt.xlim(0.7, 1)\n",
    "\n",
    "plt.savefig(\"./figures/rf_gbdt_performance.pdf\", bbox_inches=\"tight\", pad_inches=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99dab3",
   "metadata": {},
   "source": [
    "## Hard Splitting Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63a04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:50:35.224819Z",
     "start_time": "2024-05-10T15:50:35.221297Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    acc_dicts_hard = []\n",
    "    for alpha in tqdm([1e0, 1e1, 1e2, 1e3], leave=False):\n",
    "        kernel_soft = soft_kernel(X, depth=3, alpha=alpha, beta=0.5)\n",
    "        kernels_aaa, kernels_aai, patterns = extract_kernels(X, alpha=alpha, beta=0.5, degree=3)\n",
    "        for repeat in tqdm(range(4), leave=False):\n",
    "            test_index, train_index = fold[repeat * 2], fold[repeat * 2 + 1]\n",
    "            assert len(test_index) > len(train_index)\n",
    "            mkl = EasyMKL()\n",
    "\n",
    "            train_kernels_aaa = [i[train_index][:, train_index] for i in kernels_aaa]\n",
    "            train_kernels_aai = [i[train_index][:, train_index] for i in kernels_aai]\n",
    "            ker_matrix_aaa = mkl.combine_kernels(train_kernels_aaa, y[train_index])\n",
    "            ker_matrix_aai = mkl.combine_kernels(train_kernels_aai, y[train_index])\n",
    "\n",
    "            optimal = get_optimal_weight(len(ker_matrix_aaa.weights))\n",
    "\n",
    "            acc_dict_hard = benchmark(kernels_aaa, kernels_aai, kernel_soft, y, train_index, test_index, alpha, beta, repeat, optimal)\n",
    "            acc_dicts_hard.append(acc_dict_hard)\n",
    "  \n",
    "    with open('acc_dicts_hard.pkl', 'wb') as file:\n",
    "        pickle.dump(acc_dicts_hard, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd66a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:00.151648Z",
     "start_time": "2024-05-10T15:55:00.146536Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('acc_dicts_hard.pkl', 'rb') as file:\n",
    "    acc_dicts_hard= pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a0294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:55:02.360802Z",
     "start_time": "2024-05-10T15:55:00.411725Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "df = pd.DataFrame(acc_dicts_hard)\n",
    "\n",
    "results = df.groupby(by=[\"alpha\", \"beta\"]).mean()[\"aaa_benchmark\"].values\n",
    "labels = ['$10^0$', '$10^1$', '$10^2$', '$10^3$']\n",
    "\n",
    "rf3_mean = forest_mean[\"rf_3_1000\"]\n",
    "rf3_std = forest_std[\"rf_3_1000\"]\n",
    "rfmax_mean = forest_mean[\"rf_None_1000\"]\n",
    "rfmax_std = forest_std[\"rf_None_1000\"]\n",
    "gbdt3_mean = forest_mean[\"gbdt_3_1000\"]\n",
    "gbdt3_std = forest_std[\"gbdt_3_1000\"]\n",
    "gbdtmax_mean = forest_mean[\"gbdt_None_1000\"]\n",
    "gbdtmax_std = forest_std[\"gbdt_None_1000\"]\n",
    "\n",
    "\n",
    "plt.bar(labels, results)\n",
    "x_range = np.linspace(-0.5, len(labels) - 0.5, 100)\n",
    "plt.plot(np.arange(100000)-0.5, [rf3_mean]*100000, color=\"green\", linestyle=(3, (6, 6)), alpha=0.7, label=\"RF(max_depth=3)\", linewidth=1.5)\n",
    "plt.plot(np.arange(100000)-0.5, [rfmax_mean]*100000, color=\"green\", linestyle=(3, (1, 1)), alpha=0.7, label=\"RF(max_depth=None)\", linewidth=1.5)\n",
    "plt.plot(np.arange(100000)-0.5, [gbdt3_mean]*100000, color=\"orange\", linestyle=(0, (6,6)),  alpha=0.7, label=\"GBDT(max_depth=3)\", linewidth=1.5)\n",
    "plt.plot(np.arange(100000)-0.5, [gbdtmax_mean]*100000, color=\"orange\", linestyle=(0, (1,1)),  alpha=0.7, label=\"GBDT(max_depth=None)\", linewidth=1.5)\n",
    "\n",
    "plt.fill_between(np.arange(100000)-0.5, rf3_mean-rf3_std, rf3_mean+rf3_std, color='green', alpha=0.1)\n",
    "plt.fill_between(np.arange(100000)-0.5, rfmax_mean-rfmax_std, rfmax_mean+rfmax_std, color='green', alpha=0.1)\n",
    "plt.fill_between(np.arange(100000)-0.5, gbdt3_mean-gbdt3_std, gbdt3_mean+gbdt3_std, color='orange', alpha=0.1)\n",
    "plt.fill_between(np.arange(100000)-0.5, gbdtmax_mean-gbdtmax_std, gbdtmax_mean+gbdtmax_std, color='orange', alpha=0.1)\n",
    "\n",
    "plt.xlabel(\"$\\\\alpha$\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"AAA (Benchmark)\")\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.xlim(-0.5, len(labels) - 0.5)\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "alpha_values = [1e0, 1e1, 1e2, 1e3]\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "labels = ['$\\\\alpha=10^0$', '$\\\\alpha=10^1$', '$\\\\alpha=10^2$', '$\\\\alpha=10^3$']\n",
    "\n",
    "for alpha, color, label in zip(alpha_values, colors, labels):\n",
    "    x = np.linspace(-0.5, 0.5, 100000)\n",
    "    plt.plot(x, 0.5 * special.erf(alpha * x) + 0.5, color=color, label=label)\n",
    "\n",
    "plt.xlabel('$c$')\n",
    "plt.ylabel('$\\sigma(c)$')\n",
    "plt.grid(linestyle=\"dotted\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./figures/large_alpha.pdf\", bbox_inches=\"tight\", pad_inches=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d66d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
